# ‚ö° OTIMIZA√á√ÉO MEM√ìRIA E CONCORR√äNCIA
from dotenv import load_dotenv
from collections import defaultdict, deque
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import logging

load_dotenv()

# üîç Setup b√°sico de logging para produ√ß√£o
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

def criar_helena_recepcao():
    """Helena Recepcionista - Produ√ß√£o otimizada com hist√≥rico leve e lazy loading seguro."""

    # ‚ö° Lazy load das depend√™ncias e modelo
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© Helena, recepcionista virtual especializada em GRC para o setor p√∫blico brasileiro.

**SEU PAPEL:**
Voc√™ √© uma RECEPCIONISTA, n√£o uma executora. Sua fun√ß√£o √©:
1. Dar boas-vindas e entender a necessidade do usu√°rio
2. DIRECIONAR o usu√°rio para o produto correto
3. Responder d√∫vidas GERAIS sobre GRC (conceitos, normas, orienta√ß√µes)

‚ùå N√ÉO execute tarefas t√©cnicas (mapear processos, criar POPs, analisar riscos etc.)
‚úÖ SEMPRE redirecione o usu√°rio ao produto adequado.

**PRODUTOS DISPON√çVEIS:**
- üß© P1: Gerador de POP ‚Üí "Acesse o Gerador de POP para come√ßar!"
- üß† P5: An√°lise de Riscos ‚Üí "V√° para An√°lise de Riscos!"
- üîÑ P2: Gerador de Fluxograma ‚Üí "Use o Gerador de Fluxograma!"

Em desenvolvimento: P3 (Dashboard), P4 (Conformidade), P6‚ÄìP11.

**EXEMPLOS:**
User: "Quero mapear meu processo de an√°lise de benef√≠cios"
Helena: "Perfeito! Use o **Gerador de POP**. L√° eu te guio passo a passo! üéØ"

User: "Como identifico riscos no meu setor?"
Helena: "Para isso, use o produto **An√°lise de Riscos**. Clique no card correspondente no menu! üìä"

Hist√≥rico: {historico}
"""),
        ("human", "{input}")
    ])

    chain = prompt | llm
    historico_conversas = defaultdict(lambda: deque(maxlen=6))

    def responder(mensagem: str, session_id: str = "default"):
        try:
            # üìä Log entrada (analytics)
            session_short = session_id[:8] if len(session_id) > 8 else session_id
            msg_preview = mensagem[:60] + ('...' if len(mensagem) > 60 else '')
            logging.info(f"[Helena Recep√ß√£o] IN  [{session_short}...] {msg_preview}")

            historico = "\n".join(historico_conversas[session_id]) or "Primeira intera√ß√£o."
            resposta = chain.invoke({"input": mensagem, "historico": historico})

            historico_conversas[session_id].append(f"User: {mensagem}")
            historico_conversas[session_id].append(f"Helena: {resposta.content}")

            # üìä Log sa√≠da (analytics)
            resp_preview = resposta.content[:60] + ('...' if len(resposta.content) > 60 else '')
            logging.info(f"[Helena Recep√ß√£o] OUT [{session_short}...] {resp_preview}")

            return resposta.content

        except Exception as e:
            session_short = session_id[:8] if len(session_id) > 8 else session_id
            logging.error(f"[Helena Recep√ß√£o] ERR [{session_short}...] {type(e).__name__}: {str(e)}")
            return "‚ö†Ô∏è Ocorreu um problema tempor√°rio. Pode tentar novamente em instantes?"

    return responder


# ‚ö° LAZY INSTANCE: apenas quando usada
_helena_recepcao_instance = None

def helena_recepcao(mensagem: str, session_id: str = "default"):
    """Fun√ß√£o wrapper para lazy loading da inst√¢ncia Helena Recep√ß√£o"""
    global _helena_recepcao_instance
    if _helena_recepcao_instance is None:
        _helena_recepcao_instance = criar_helena_recepcao()
    return _helena_recepcao_instance(mensagem, session_id)
