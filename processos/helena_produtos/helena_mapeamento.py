from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory

def criar_helena_mapeamento():
    """
    Cria Helena como parceira de preenchimento do POP.
    Ela responde de forma emp√°tica, clara e motivadora.
    Mant√©m mem√≥ria da conversa para dar continuidade real.
    Helena s√≥ muda de assunto quando o usu√°rio confirmar que a d√∫vida foi resolvida.
    """

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.6)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "Voc√™ √© Helena, assistente especialista em mapeamento de processos e POPs. "
         "Seu papel √© ser parceira do usu√°rio: clara, paciente, emp√°tica e bem-humorada. "
         "O usu√°rio est√° preenchendo os campos de um POP e voc√™ deve ajud√°-lo com explica√ß√µes simples, exemplos pr√°ticos e incentivo. "
         "Mantenha foco no campo atual at√© o usu√°rio confirmar que a d√∫vida foi resolvida. "
         "Nunca repita a mesma explica√ß√£o: traga novos exemplos, met√°foras ou perguntas de apoio. "
         "S√≥ avance para outro campo se o usu√°rio pedir explicitamente. "
         "Use humor leve e reconhecimento do esfor√ßo quando fizer sentido. "
         "No fim de cada resposta, confirme com o usu√°rio: 'Essa etapa ficou clara?' ou 'Podemos seguir?'. "
        ),
        ("human", "{input}")
    ])

    # üîπ Mem√≥ria para manter hist√≥rico e contexto
    memory = ConversationBufferMemory(return_messages=True)

    # üîπ Chain combina LLM + prompt + mem√≥ria
    chain = LLMChain(
        llm=llm,
        prompt=prompt,
        memory=memory
    )

    def responder(mensagem: str):
        resposta = chain.run(input=mensagem)
        return resposta

    return responder

helena_mapeamento = criar_helena_mapeamento()