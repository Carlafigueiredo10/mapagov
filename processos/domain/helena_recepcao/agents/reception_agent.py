import copy
from typing import Dict, Any
from langchain_openai import ChatOpenAI
from processos.domain.helena_semantic_planner import HelenaSemanticPlanner

class ReceptionAgent:
    """
    Helena Reception Agent ‚Äì recepcionista virtual para direcionamento GRC.

    Papel: RECEPCIONISTA, n√£o executora
    - Dar boas-vindas e entender necessidade
    - Direcionar para produto correto
    - Responder d√∫vidas gerais sobre GRC

    Usa HelenaSemanticPlanner para interpreta√ß√£o sem√¢ntica robusta.
    """

    PRODUTOS = {
        "pop": {
            "nome": "Gerador de POP",
            "emoji": "üß©",
            "codigo": "P1",
            "descricao": "Mapear processos e gerar Procedimentos Operacionais Padr√£o",
            "keywords": ["pop", "procedimento", "mapear", "processo", "documentar", "passo a passo"]
        },
        "fluxograma": {
            "nome": "Gerador de Fluxograma",
            "emoji": "üîÑ",
            "codigo": "P2",
            "descricao": "Criar fluxogramas visuais de processos",
            "keywords": ["fluxograma", "diagrama", "fluxo", "visual", "mermaid", "etapas"]
        },
        "riscos": {
            "nome": "An√°lise de Riscos",
            "emoji": "üß†",
            "codigo": "P5",
            "descricao": "Identificar e analisar riscos em processos (GRC)",
            "keywords": ["risco", "an√°lise", "grc", "controle", "conformidade", "auditoria"]
        },
        "dashboard": {
            "nome": "Dashboard",
            "emoji": "üìä",
            "codigo": "P3",
            "descricao": "Visualizar indicadores e m√©tricas",
            "keywords": ["dashboard", "indicador", "m√©trica", "painel", "visualizar"],
            "status": "em_desenvolvimento"
        }
    }

    def __init__(self, llm: ChatOpenAI | None = None):
        self.llm = llm or ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
        self.planner = HelenaSemanticPlanner()

    # =========================================================================
    # SHIM DE COMPATIBILIDADE COM ORQUESTRADOR
    # =========================================================================

    def processar_mensagem(self, mensagem: str, estrutura_atual: Dict[str, Any] | None) -> Dict[str, Any]:
        """
        M√©todo de compatibilidade com o orquestrador.

        Retorna: {'campo', 'valor', 'proxima_pergunta', 'completo', 'percentual', 'validacao_ok'}
        """
        contexto = self._init_contexto(estrutura_atual)
        bruto = self.processar(mensagem, contexto)
        return self._to_orchestrator(bruto, contexto)

    # =========================================================================
    # L√ìGICA INTERNA (FORMATO SEM√ÇNTICO)
    # =========================================================================

    def processar(self, mensagem: str, contexto: Dict[str, Any]) -> Dict[str, Any]:
        """
        Processa mensagem do usu√°rio de forma conversacional.

        Returns formato interno:
            {
                'acao': str,
                'texto': str,
                'payload': dict
            }
        """
        msg = mensagem.lower().strip()

        # Inicializa estrutura
        contexto.setdefault("interacoes", 0)
        contexto["interacoes"] += 1

        # üëã Boas-vindas (primeira intera√ß√£o com sauda√ß√£o)
        if contexto["interacoes"] == 1:
            if any(p in msg for p in ["oi", "ol√°", "bom dia", "boa tarde", "come√ßar", "iniciar", "start", "help"]):
                return {
                    "acao": "boas_vindas",
                    "texto": (
                        "Oi! üëã Bem-vindo √† Helena GRC!\n\n"
                        "Sou a recepcionista virtual. Posso te ajudar a entender sobre GRC "
                        "e te direcionar ao produto certo.\n\n"
                        "**Produtos dispon√≠veis:**\n"
                        "üß© **P1: Gerador de POP** - Mapear e documentar processos\n"
                        "üîÑ **P2: Fluxograma** - Criar diagramas visuais\n"
                        "üß† **P5: An√°lise de Riscos** - GRC e conformidade\n"
                        "üìä **P3: Dashboard** (em breve) - Indicadores e m√©tricas\n\n"
                        "Me conta: o que voc√™ precisa fazer hoje? Pode perguntar qualquer coisa!"
                    ),
                    "payload": {}
                }

        # ‚ùì PRIMEIRO: Verificar se √© uma PERGUNTA (antes de detectar produto)
        eh_pergunta = self._eh_pergunta(msg)

        if eh_pergunta:
            # Usa LLM para responder de forma conversacional
            return self._responder_pergunta(mensagem, contexto)

        # üéØ SEGUNDO: Detecta inten√ß√£o de USAR um produto
        if self._quer_usar_produto(msg):
            produto_detectado = self._detectar_produto(msg)

            if produto_detectado:
                produto = self.PRODUTOS[produto_detectado]

                # Se produto em desenvolvimento
                if produto.get("status") == "em_desenvolvimento":
                    return {
                        "acao": "produto_indisponivel",
                        "texto": (
                            f"{produto['emoji']} **{produto['nome']}** ({produto['codigo']}) est√° em desenvolvimento.\n\n"
                            "Por enquanto, posso te ajudar com:\n"
                            "üß© Gerador de POP\n"
                            "üîÑ Fluxograma\n"
                            "üß† An√°lise de Riscos\n\n"
                            "Qual desses te interessa?"
                        ),
                        "payload": {"produto_solicitado": produto_detectado}
                    }

                # Produto dispon√≠vel - direciona
                return {
                    "acao": "direcionar_produto",
                    "texto": (
                        f"Perfeito! Para isso voc√™ precisa do **{produto['nome']}** {produto['emoji']}\n\n"
                        f"**{produto['descricao']}**\n\n"
                        f"üëâ Clique no card **{produto['codigo']}** no menu para come√ßar!\n\n"
                        "Precisa de mais alguma coisa?"
                    ),
                    "payload": {
                        "produto": produto_detectado,
                        "produto_codigo": produto['codigo'],
                        "produto_nome": produto['nome']
                    }
                }

        # ü§ñ TERCEIRO: Tenta responder com LLM para qualquer outra coisa
        return self._responder_pergunta(mensagem, contexto)

    def _eh_pergunta(self, msg: str) -> bool:
        """Detecta se a mensagem √© uma pergunta."""
        indicadores_pergunta = [
            "o que √©", "o que s√£o", "o que significa",
            "como funciona", "como fa√ßo", "como fazer",
            "qual √©", "qual a", "quais s√£o", "quais os",
            "por que", "porque", "pra que", "para que",
            "quando", "onde", "quem",
            "explica", "me explica", "pode explicar",
            "me fala", "me conta", "me diz",
            "o que", "?",
            "significa", "conceito", "defini√ß√£o",
            "diferen√ßa entre", "diferente de"
        ]
        return any(ind in msg for ind in indicadores_pergunta)

    def _quer_usar_produto(self, msg: str) -> bool:
        """Detecta se o usu√°rio quer USAR um produto (n√£o s√≥ perguntar sobre)."""
        indicadores_uso = [
            "quero", "preciso", "vou", "vamos",
            "fazer", "criar", "gerar", "mapear",
            "iniciar", "come√ßar", "usar", "utilizar",
            "me ajuda a", "ajuda a", "ajude-me",
            "pode fazer", "faz um", "faz uma",
            "elaborar", "desenvolver", "construir"
        ]
        return any(ind in msg for ind in indicadores_uso)

    def _responder_pergunta(self, mensagem: str, contexto: Dict[str, Any]) -> Dict[str, Any]:
        """Usa LLM para responder perguntas de forma conversacional."""

        # Contexto sobre os produtos para a LLM
        produtos_info = "\n".join([
            f"- {p['emoji']} {p['nome']} ({p['codigo']}): {p['descricao']}"
            for p in self.PRODUTOS.values()
        ])

        prompt = f"""Voc√™ √© Helena, uma assistente virtual especializada em GRC (Governan√ßa, Riscos e Conformidade).

Seu papel √© CONVERSAR e EXPLICAR conceitos de forma clara e did√°tica. Seja amig√°vel e prestativa.

**Produtos dispon√≠veis na plataforma:**
{produtos_info}

**Instru√ß√µes:**
1. Responda a pergunta do usu√°rio de forma clara e educativa
2. Se a pergunta for sobre um tema relacionado a um produto, explique o conceito primeiro
3. Ao final, sugira gentilmente o produto relacionado se fizer sentido (n√£o force)
4. Use linguagem simples e acess√≠vel
5. Resposta deve ter no m√°ximo 150 palavras
6. Use markdown para formata√ß√£o (negrito, listas)

**Pergunta do usu√°rio:** {mensagem}

Responda de forma conversacional:"""

        try:
            resposta = self.llm.invoke(prompt)
            texto_resposta = resposta.content if hasattr(resposta, 'content') else str(resposta)

            return {
                "acao": "conversa",
                "texto": texto_resposta,
                "payload": {}
            }
        except Exception as e:
            # Fallback se LLM falhar
            return {
                "acao": "conversa",
                "texto": (
                    "Boa pergunta! Infelizmente tive um probleminha t√©cnico.\n\n"
                    "Posso te ajudar de outra forma:\n"
                    "üß© **Gerador de POP** - documentar processos\n"
                    "üîÑ **Fluxograma** - criar diagramas\n"
                    "üß† **An√°lise de Riscos** - GRC e conformidade\n\n"
                    "Qual te interessa?"
                ),
                "payload": {"erro": str(e)}
            }

    def _detectar_produto(self, mensagem: str) -> str | None:
        """Detecta qual produto o usu√°rio precisa baseado em keywords"""

        msg_lower = mensagem.lower()

        # Conta matches para cada produto
        matches = {}
        for produto_id, produto in self.PRODUTOS.items():
            count = sum(1 for keyword in produto["keywords"] if keyword in msg_lower)
            if count > 0:
                matches[produto_id] = count

        # Retorna produto com mais matches
        if matches:
            return max(matches, key=matches.get)

        return None

    # =========================================================================
    # CONVERSORES DE FORMATO
    # =========================================================================

    def _init_contexto(self, estrutura_atual: Dict[str, Any] | None) -> Dict[str, Any]:
        """Inicializa contexto a partir da estrutura do orquestrador."""
        ctx = copy.deepcopy(estrutura_atual or {})
        ctx.setdefault("interacoes", 0)
        return ctx

    def _to_orchestrator(self, bruto: Dict[str, Any], contexto: Dict[str, Any]) -> Dict[str, Any]:
        """
        Converte formato interno {acao, texto, payload} para contrato do orquestrador.
        """
        acao = bruto.get("acao")
        texto = bruto.get("texto", "")
        payload = bruto.get("payload", {})

        # Mapeamento de a√ß√µes ‚Üí campo/valor
        mapeamento = {
            "boas_vindas": ("inicio", None, True),
            "direcionar_produto": ("direcionar", payload.get("produto"), True),
            "orientacao_grc": ("orientacao", None, True),
            "produto_indisponivel": ("indisponivel", payload.get("produto_solicitado"), True),
            "pedir_clarificacao": ("clarificacao", None, True),
            "conversa": ("conversa", None, True),
        }

        campo, valor, validacao_ok = mapeamento.get(acao, ("neutro", None, True))

        return {
            "campo": campo,
            "valor": valor,
            "proxima_pergunta": texto,
            "completo": False,  # Recep√ß√£o nunca "completa", √© sempre cont√≠nua
            "percentual": 100,  # Sempre 100% porque n√£o tem fluxo linear
            "validacao_ok": validacao_ok
        }


# Alias para compatibilidade
HelenaReceptionAgent = ReceptionAgent
